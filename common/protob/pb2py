#!/usr/bin/env python3
# Converts Google's protobuf python definitions of Trezor wire messages
# to plain-python objects as used in Trezor Core and python-trezor

import argparse
import importlib
import logging
import os
import shutil
import subprocess
import sys
import tempfile
from collections import namedtuple, defaultdict

import attr
import construct as c

from google.protobuf import descriptor_pb2


AUTO_HEADER = "# Automatically generated by pb2py\n"

# fmt: off
FIELD_TYPES = {
    descriptor_pb2.FieldDescriptorProto.TYPE_UINT64:  ('p.UVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_UINT32:  ('p.UVarintType', 'int'),
#    descriptor_pb2.FieldDescriptorProto.TYPE_ENUM:    ('p.UVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_SINT32:  ('p.SVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_SINT64:  ('p.SVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_STRING:  ('p.UnicodeType', 'str'),
    descriptor_pb2.FieldDescriptorProto.TYPE_BOOL:    ('p.BoolType', 'bool'),
    descriptor_pb2.FieldDescriptorProto.TYPE_BYTES:   ('p.BytesType', 'bytes'),
}
# fmt: on

ListOfSimpleValues = c.GreedyRange(
    c.Struct(
        "key" / c.VarInt,
        "value" / c.VarInt,
    )
)


def parse_protobuf_simple(data):
    """Micro-parse protobuf-encoded data.

    Assume every field is of type 0 (varint), and parse to a dict of fieldnum: value.
    """
    return {v.key >> 3: v.value for v in ListOfSimpleValues.parse(data)}


PROTOC = shutil.which("protoc")
if not PROTOC:
    print("protoc command not found")
    sys.exit(1)

PROTOC_PREFIX = os.path.dirname(os.path.dirname(PROTOC))
PROTOC_INCLUDE = os.path.join(PROTOC_PREFIX, "include")


@attr.s
class ProtoField:
    name = attr.ib()
    number = attr.ib()
    orig = attr.ib()
    repeated = attr.ib()
    required = attr.ib()
    experimental = attr.ib()
    type_name = attr.ib()
    proto_type = attr.ib()
    py_type = attr.ib()
    default_value = attr.ib()

    @property
    def optional(self):
        return not self.required and not self.repeated

    @classmethod
    def from_field(cls, descriptor, field):
        repeated = field.label == field.LABEL_REPEATED
        required = field.label == field.LABEL_REQUIRED
        experimental = bool(descriptor._get_extension(field, "experimental"))
        # ignore package path
        type_name = field.type_name.rsplit(".")[-1]

        if field.type == field.TYPE_MESSAGE:
            proto_type = py_type = type_name
        elif field.type == field.TYPE_ENUM:
            value_dict = descriptor.enum_types[type_name]
            valuestr = ", ".join(str(v) for v in value_dict.values())
            proto_type = 'p.EnumType("{}", ({}))'.format(type_name, valuestr)
            py_type = "EnumType" + type_name
        else:
            try:
                proto_type, py_type = FIELD_TYPES[field.type]
            except KeyError:
                raise ValueError(
                    "Unknown field type {} for field {}".format(field.type, field.name)
                ) from None

        if not field.HasField("default_value"):
            default_value = None
        elif field.type == field.TYPE_ENUM:
            default_value = str(descriptor.enum_types[type_name][field.default_value])
        elif field.type == field.TYPE_STRING:
            default_value = f'"{field.default_value}"'
        elif field.type == field.TYPE_BYTES:
            default_value = f'b"{field.default_value}"'
        elif field.type == field.TYPE_BOOL:
            default_value = "True" if field.default_value == "true" else "False"
        else:
            default_value = field.default_value

        return cls(
            name=field.name,
            number=field.number,
            orig=field,
            repeated=repeated,
            required=required,
            experimental=experimental,
            type_name=type_name,
            proto_type=proto_type,
            py_type=py_type,
            default_value=default_value,
        )


def protoc(files, additional_includes=()):
    """Compile code with protoc and return the data."""
    include_dirs = set()
    include_dirs.add(PROTOC_INCLUDE)
    include_dirs.update(additional_includes)

    for file in files:
        dirname = os.path.dirname(file) or "."
        include_dirs.add(dirname)
    protoc_includes = ["-I" + dir for dir in include_dirs if dir]

    # Note that we could avoid creating temp files if protoc let us write to stdout
    # directly. this is currently only possible on Unix, by passing /dev/stdout as
    # the file name. Since there's no direct Windows equivalent, not counting
    # being creative with named pipes, special-casing this is not worth the effort.
    with tempfile.TemporaryDirectory() as tmpdir:
        outfile = os.path.join(tmpdir, "DESCRIPTOR_SET")
        subprocess.check_call(
            [PROTOC, "--descriptor_set_out={}".format(outfile)]
            + protoc_includes
            + files
        )
        with open(outfile, "rb") as f:
            return f.read()


def strip_leader(s, prefix):
    """Remove given prefix from underscored name."""
    leader = prefix + "_"
    if s.startswith(leader):
        return s[len(leader) :]
    else:
        return s


def import_statement_from_path(path):
    # separate leading dots
    dot_prefix = ""
    while path.startswith("."):
        dot_prefix += "."
        path = path[1:]

    # split on remaining dots
    split_path = path.rsplit(".", maxsplit=1)
    leader, import_name = split_path[:-1], split_path[-1]

    if leader:
        from_part = dot_prefix + leader
    elif dot_prefix:
        from_part = dot_prefix
    else:
        from_part = ""

    if from_part:
        return "from {} import {}".format(from_part, import_name)
    else:
        return "import {}".format(import_name)


class Descriptor:
    def __init__(self, data, message_type="MessageType", import_path="protobuf"):
        self.descriptor = descriptor_pb2.FileDescriptorSet()
        self.descriptor.ParseFromString(data)

        self.files = self.descriptor.file

        logging.debug("found {} files".format(len(self.files)))

        # find messages and enums
        self.messages = []
        self.enums = []
        self.enum_types = defaultdict(dict)

        self.extensions = {}

        for file in self.files:
            self.messages += file.message_type
            self.enums += file.enum_type
            for message in file.message_type:
                self._nested_types_from_message(message)
            for extension in file.extension:
                self.extensions[extension.name] = extension.number

        if not self.messages and not self.enums:
            raise RuntimeError("No messages and no enums found.")

        self.message_types = self.find_message_types(message_type)
        self.protobuf_import = import_statement_from_path(import_path)

        self.out_dir = None

    def _get_extension(self, something, extension_name, default=None):
        # There doesn't seem to be a sane way to access extensions on a descriptor
        # via the google.protobuf API.
        # We do have access to descriptors of the extensions...
        extension_num = self.extensions[extension_name]
        # ...and the "options" descriptor _does_ include the extension data. But while
        # the API provides access to unknown fields, it hides the extensions.
        # What we do is re-encode the options descriptor...
        options_bytes = something.options.SerializeToString()
        # ...and re-parse it as a dict of uvarints...
        simple_values = parse_protobuf_simple(options_bytes)
        # ...and extract the value corresponding to the extension we care about.
        return simple_values.get(extension_num, default)

    def _nested_types_from_message(self, message):
        self.messages += message.nested_type
        self.enums += message.enum_type
        for nested in message.nested_type:
            self._nested_types_from_message(nested)

    def find_message_types(self, message_type):
        message_types = {}
        try:
            message_type_enum = next(e for e in self.enums if e.name == message_type)
            for value in message_type_enum.value:
                name = strip_leader(value.name, message_type)
                message_types[name] = value.number

        except StopIteration:
            # No message type found. Oh well.
            logging.warning(
                "Message IDs not found under '{}'".format(args.message_type)
            )

        return message_types

    def create_message_import(self, name):
        return "from .{0} import {0}".format(name)

    def process_subtype_imports(self, fields):
        imports = set(
            field.proto_type
            for field in fields
            if field.orig.type == field.orig.TYPE_MESSAGE
        )

        if len(imports) > 0:
            yield ""  # make isort happy
        for name in sorted(imports):
            yield self.create_message_import(name)

    def create_init_method(self, fields):
        required_fields = [f for f in fields if f.required]
        repeated_fields = [f for f in fields if f.repeated]
        optional_fields = [f for f in fields if f.optional]
        # please keep the yields aligned
        # fmt: off
        yield      "    def __init__("
        yield      "        self,"
        yield      "        *,"
        for field in required_fields:
            yield f"        {field.name}: {field.py_type},"
        for field in repeated_fields:
            yield f"        {field.name}: List[{field.py_type}] = None,"
        for field in optional_fields:
            yield f"        {field.name}: {field.py_type} = {field.default_value},"
        yield          "    ) -> None:"

        for field in repeated_fields:
            yield f"        self.{field.name} = {field.name} if {field.name} is not None else []"
        for field in required_fields + optional_fields:
            yield f"        self.{field.name} = {field.name}"
        # fmt: on

    def create_fields_method(self, fields):
        # fmt: off
        yield "    @classmethod"
        yield "    def get_fields(cls) -> Dict:"
        yield "        return {"
        for field in fields:
            comments = []
            if field.default_value is not None:
                comments.append(f"default={field.orig.default_value}")

            if comments:
                comment = "  # " + " ".join(comments)
            else:
                comment = ""

            if field.repeated:
                if field.default_value is not None:
                    raise ValueError("Repeated fields can't have default values.")
                if field.experimental:
                    raise ValueError("Repeated experimental fields are currently not supported.")
                flags = "p.FLAG_REPEATED"
            elif field.required:
                if field.default_value is not None:
                    raise ValueError("Required fields can't have default values.")
                if field.experimental:
                    raise ValueError("Required fields can't be experimental.")
                flags = "p.FLAG_REQUIRED"
            elif field.experimental:
                if field.default_value is not None:
                    raise ValueError("Experimental fields can't have default values.")
                flags = "p.FLAG_EXPERIMENTAL"
            else:
                flags = field.default_value

            yield "            {num}: ('{name}', {type}, {flags}),{comment}".format(
                num=field.number,
                name=field.name,
                type=field.proto_type,
                flags=flags,
                comment=comment,
            )

        yield "        }"
        # fmt: on

    def process_message(self, message, include_deprecated=False):
        logging.debug("Processing message {}".format(message.name))

        msg_id = self._get_extension(message, "wire_type")
        if msg_id is None:
            msg_id = self.message_types.get(message.name)

        unstable = self._get_extension(message, "unstable")

        # "from .. import protobuf as p"
        yield self.protobuf_import + " as p"

        fields = [ProtoField.from_field(self, field) for field in message.field]
        if not include_deprecated:
            fields = [field for field in fields if not field.orig.options.deprecated]

        yield from self.process_subtype_imports(fields)

        yield ""
        yield "if __debug__:"
        yield "    try:"
        yield "        from typing import Dict, List  # noqa: F401"
        yield "        from typing_extensions import Literal  # noqa: F401"

        all_enums = [field for field in fields if field.type_name in self.enum_types]
        for field in all_enums:
            allowed_values = self.enum_types[field.type_name].values()
            valuestr = ", ".join(str(v) for v in sorted(allowed_values))
            yield "        {} = Literal[{}]".format(field.py_type, valuestr)

        yield "    except ImportError:"
        yield "        pass"

        yield ""
        yield ""
        yield "class {}(p.MessageType):".format(message.name)

        if msg_id is not None:
            yield "    MESSAGE_WIRE_TYPE = {}".format(msg_id)

        if unstable is not None:
            yield "    UNSTABLE = True"

        if fields:
            yield ""
            yield from self.create_init_method(fields)
            yield ""
            yield from self.create_fields_method(fields)

        if not fields and not msg_id:
            yield "    pass"

    def process_enum(self, enum):
        logging.debug("Processing enum {}".format(enum.name))

        # file header
        yield "if __debug__:"
        yield "    try:"
        yield "        from typing_extensions import Literal  # noqa: F401"
        yield "    except ImportError:"
        yield "        pass"
        yield ""

        for value in enum.value:
            # Remove type name from the beginning of the constant
            # For example "PinMatrixRequestType_Current" -> "Current"
            enum_prefix = enum.name
            name = value.name
            name = strip_leader(name, enum_prefix)

            # If type ends with *Type, but constant use type name without *Type, remove it too :)
            # For example "ButtonRequestType & ButtonRequest_Other" => "Other"
            if enum_prefix.endswith("Type"):
                enum_prefix, _ = enum_prefix.rsplit("Type", 1)
                name = strip_leader(name, enum_prefix)

            self.enum_types[enum.name][value.name] = value.number
            yield f"{name}: Literal[{value.number}] = {value.number}"

    def process_messages(self, messages, include_deprecated=False):
        for message in sorted(messages, key=lambda m: m.name):
            self.write_to_file(
                message.name, self.process_message(message, include_deprecated)
            )

    def process_enums(self, enums):
        for enum in sorted(enums, key=lambda e: e.name):
            self.write_to_file(enum.name, self.process_enum(enum))

    def write_to_file(self, name, out):
        # Write generated sourcecode to given file
        logging.debug("Writing file {}.py".format(name))
        with open(os.path.join(self.out_dir, name + ".py"), "w") as f:
            f.write(AUTO_HEADER)
            f.write("# fmt: off\n")
            for line in out:
                f.write(line + "\n")

    def write_init_py(self):
        filename = os.path.join(self.out_dir, "__init__.py")
        with open(filename, "w") as init_py:
            init_py.write(AUTO_HEADER)
            init_py.write("# fmt: off\n\n")
            for message in sorted(self.messages, key=lambda m: m.name):
                init_py.write(self.create_message_import(message.name) + "\n")
            for enum in sorted(self.enums, key=lambda m: m.name):
                init_py.write("from . import {}\n".format(enum.name))

    def write_classes(self, out_dir, init_py=True, include_deprecated=False):
        self.out_dir = out_dir
        self.process_enums(self.enums)
        self.process_messages(self.messages, include_deprecated)
        if init_py:
            self.write_init_py()

    def write_qstrs(self, qstr_path, include_deprecated=False):
        logging.debug("Writing qstrings to {}".format(qstr_path))
        with open(qstr_path, "w") as f:
            for name in self.collect_msg_and_field_names(include_deprecated):
                f.write("Q({})\n".format(name))

    def collect_msg_and_field_names(self, include_deprecated=False):
        names = set()
        for message in self.messages:
            names.add(message.name)
            for field in message.field:
                if not include_deprecated and field.options.deprecated:
                    continue
                names.add(field.name)
        return sorted(names)

    def write_blobs(self, blob_dir, qstr_defs, include_deprecated=False):
        logging.debug("Writing blobs to {}".format(blob_dir))
        blob_enums, blob_msgs, blob_names, blob_wire = self.build_blobs(
            qstr_defs, include_deprecated
        )
        with open(os.path.join(blob_dir, "proto_enums.data"), "wb") as f:
            f.write(blob_enums)
        with open(os.path.join(blob_dir, "proto_msgs.data"), "wb") as f:
            f.write(blob_msgs)
        with open(os.path.join(blob_dir, "proto_names.data"), "wb") as f:
            f.write(blob_names)
        with open(os.path.join(blob_dir, "proto_wire.data"), "wb") as f:
            f.write(blob_wire)

    def build_blobs(self, qstr_defs, include_deprecated=False):
        enums_type = c.Struct(
            "enums"
            / c.GreedyRange(
                c.Struct(
                    "count" / c.Byte,
                    "vals" / c.Array(c.this.count, c.Int16ul),
                )
            ),
        )
        msgs_type = c.Struct(
            "msgs"
            / c.GreedyRange(
                c.Struct(
                    "fields_count" / c.Byte,
                    "defaults_size" / c.Byte,
                    "wire_id" / c.Int16ul,  # 0xFFFF iff unset
                    "fields"
                    / c.Array(
                        c.this.fields_count,
                        c.Struct(
                            "tag" / c.Byte,
                            "flags_and_type"
                            / c.BitStruct(
                                "is_required" / c.Flag,
                                "is_repeated" / c.Flag,
                                "is_experimental" / c.Flag,
                                c.Padding(1),
                                "type" / c.BitsInteger(4),
                            ),
                            "enum_or_msg_offset" / c.Int16ul,
                            "name" / c.Int16ul,
                        ),
                    ),
                    "defaults"
                    / c.Array(
                        c.this.defaults_size,
                        c.Byte,
                    ),
                )
            ),
        )
        names_type = c.Struct(
            "msgs"
            / c.GreedyRange(
                c.Struct(  # sorted by msg_name
                    "msg_name" / c.Int16ul,
                    "msg_offset" / c.Int16ul,
                )
            )
        )
        wire_type = c.Struct(
            "msgs"
            / c.GreedyRange(
                c.Struct(  # sorted by wire_id
                    "wire_id" / c.Int16ul,
                    "msg_offset" / c.Int16ul,
                )
            )
        )

        qstr_map = self.build_qstr_map(qstr_defs)
        enum_map = self.build_enum_offset_map()
        msg_map = self.build_msg_offset_map(include_deprecated)

        enums = enums_type.build(
            dict(
                enums=self.build_blob_enums(),
            )
        )
        msgs = msgs_type.build(
            dict(
                msgs=self.build_blob_msgs(
                    qstr_map, enum_map, msg_map, include_deprecated
                ),
            )
        )
        names = names_type.build(
            dict(
                msgs=self.build_blob_names(qstr_map, msg_map),
            )
        )
        wire = wire_type.build(
            dict(
                msgs=self.build_blob_wire(msg_map),
            )
        )

        return enums, msgs, names, wire

    def build_qstr_map(self, qstr_defs):
        qstr_map = {}
        qstr = 0
        with open(qstr_defs, "r") as f:
            for line in f:
                line = line.strip()
                if not line.startswith("QDEF"):
                    continue
                # Example:
                # QDEF(MP_QSTR_copysign, (const byte*)"\x33\x14\x08" "copysign")
                quote = line.rindex('"', 0, -2)
                name = line[quote + 1 : -2]
                qstr_map[name] = qstr
                # QSTR defs are rolled out into an enum in py/qstr.h, the numeric
                # value is simply an incremented integer.
                qstr += 1
        return qstr_map

    def build_enum_offset_map(self):
        enum_map = {}
        cursor = 0
        for enum in sorted(self.enums, key=lambda e: e.name):
            enum_map[enum.name] = cursor
            # TODO: calculate from the actual EnumDef type
            count = len(enum.value)
            enum_size = 1 + count * 2
            cursor += enum_size
        return enum_map

    def build_msg_offset_map(self, include_deprecated):
        msg_map = {}
        cursor = 0
        for msg in sorted(self.messages, key=lambda m: m.name):
            msg_map[msg.name] = cursor
            fields_count = 0
            defaults_size = 0
            for field in sorted(msg.field, key=lambda f: f.number):
                if not include_deprecated and field.options.deprecated:
                    continue
                fields_count += 1
                if field.default_value != "":
                    item = self.encode_field_default(field)
                    defaults_size += len(item)
            # TODO: calculate from the actual MsgDef type
            fields_size = fields_count * (1 + 1 + 2 + 2)
            msg_size = 1 + 1 + 2 + fields_size + defaults_size
            cursor += msg_size
        return msg_map

    def build_blob_enums(self):
        enums = []
        for enum in sorted(self.enums, key=lambda e: e.name):
            vals = []
            for val in enum.value:
                vals.append(val.number)
            enums.append(dict(count=len(vals), vals=vals))
        return enums

    def build_blob_msgs(self, qstr_map, enum_map, msg_map, include_deprecated):
        msgs = []
        for msg in sorted(self.messages, key=lambda m: m.name):
            defaults = []
            fields = []

            wire_id = self._get_extension(msg, "wire_type")
            if wire_id is None:
                wire_id = self.message_types.get(msg.name)
            if wire_id == 0xFFFF:
                raise ValueError("Forbidden wire ID")
            elif wire_id is None:
                wire_id = 0xFFFF

            for field in sorted(msg.field, key=lambda f: f.number):
                if not include_deprecated and field.options.deprecated:
                    continue
                if field.name == "wire_id":
                    # Message wire IDs are kept under the "wire_id" field name, forbid
                    # regular fields from colliding.
                    raise ValueError("Forbidden field name")
                field_type, ref_offset = self.encode_field_type(
                    field, enum_map, msg_map
                )
                proto_field = ProtoField.from_field(self, field)
                fields.append(
                    dict(
                        tag=field.number,
                        flags_and_type=dict(
                            is_required=proto_field.required,
                            is_repeated=proto_field.repeated,
                            is_experimental=proto_field.experimental,
                            type=field_type,
                        ),
                        enum_or_msg_offset=ref_offset,
                        name=qstr_map[field.name],
                    )
                )
                if field.default_value != "":
                    item = self.encode_field_default(field)
                    defaults.append(item)
            defaults = b"".join(defaults)
            msgs.append(
                dict(
                    fields_count=len(fields),
                    defaults_size=len(defaults),
                    wire_id=wire_id,
                    fields=fields,
                    defaults=defaults,
                )
            )
        return msgs

    def encode_field_type(self, field, enum_map, msg_map):
        T_UVARINT = 0
        T_SVARINT = 1
        T_BOOL = 2
        T_BYTES = 3
        T_STRING = 4
        T_ENUM = 5
        T_MSG = 6
        type_name = field.type_name.rsplit(".")[-1]  # ignore package
        if field.type == field.TYPE_UINT32 or field.type == field.TYPE_UINT64:
            return (T_UVARINT, 0)
        elif field.type == field.TYPE_SINT32 or field.type == field.TYPE_SINT64:
            return (T_SVARINT, 0)
        elif field.type == field.TYPE_BOOL:
            return (T_BOOL, 0)
        elif field.type == field.TYPE_BYTES:
            return (T_BYTES, 0)
        elif field.type == field.TYPE_STRING:
            return (T_STRING, 0)
        elif field.type == field.TYPE_ENUM:
            return (T_ENUM, enum_map[type_name])
        elif field.type == field.TYPE_MESSAGE:
            return (T_MSG, msg_map[type_name])
        else:
            raise ValueError(
                "Unknown field type {} for field {}".format(field.type, field.name)
            )

    def encode_field_default(self, field):
        # TODO: encode the default field value as protobuf
        return b""

    def build_blob_names(self, qstr_map, msg_map):
        msgs = []
        for msg in sorted(self.messages, key=lambda m: m.name):
            msgs.append(
                dict(
                    msg_name=qstr_map[msg.name],
                    msg_offset=msg_map[msg.name],
                )
            )
        return sorted(msgs, key=lambda m: m["msg_name"])

    def build_blob_wire(self, msg_map):
        msgs = []
        for msg in sorted(self.messages, key=lambda m: m.name):
            wire_id = self._get_extension(msg, "wire_type")
            if wire_id is None:
                wire_id = self.message_types.get(msg.name)
            if wire_id is not None:
                msgs.append(
                    dict(
                        wire_id=wire_id,
                        msg_offset=msg_map[msg.name],
                    )
                )
        return sorted(msgs, key=lambda m: m["wire_id"])


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # fmt: off
    parser.add_argument("proto", nargs="+", help="Protobuf definition files")
    parser.add_argument("-o", "--out-dir", help="Directory for generated source code")
    parser.add_argument("-P", "--protobuf-module", default="protobuf", help="Name of protobuf module")
    parser.add_argument("-l", "--no-init-py", action="store_true", help="Do not generate __init__.py with list of modules")
    parser.add_argument("--message-type", default="MessageType", help="Name of enum with message IDs")
    parser.add_argument("-I", "--protoc-include", action="append", help="protoc include path")
    parser.add_argument("-v", "--verbose", action="store_true", help="Print debug messages")
    parser.add_argument("-d", "--include-deprecated", action="store_true", help="Include deprecated fields")
    parser.add_argument("--qstr-file", help="Collect QSTRs into a file")
    parser.add_argument("--qstr-defs", help="Input file specifying QSTR values for blob dumping")
    parser.add_argument("--blob", action="store_true", help="Dump the definitions in a compact format, needs --qstr-defs")
    # fmt: on
    args = parser.parse_args()

    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)

    protoc_includes = args.protoc_include or (os.environ.get("PROTOC_INCLUDE"),)
    descriptor_proto = protoc(args.proto, protoc_includes)
    descriptor = Descriptor(descriptor_proto, args.message_type, args.protobuf_module)

    with tempfile.TemporaryDirectory() as tmpdir:
        descriptor.write_classes(tmpdir, not args.no_init_py, args.include_deprecated)

        for filename in os.listdir(args.out_dir):
            pathname = os.path.join(args.out_dir, filename)
            try:
                with open(pathname, "r") as f:
                    if next(f, None) == AUTO_HEADER:
                        os.unlink(pathname)
            except Exception:
                pass

        for filename in os.listdir(tmpdir):
            src = os.path.join(tmpdir, filename)
            shutil.copy(src, args.out_dir)

        if args.qstr_file:
            qstr_path = os.path.join(args.out_dir, args.qstr_file)
            qstr_path = os.path.abspath(qstr_path)
            descriptor.write_qstrs(qstr_path, args.include_deprecated)

        if args.blob and args.qstr_defs:
            descriptor.write_blobs(
                args.out_dir, args.qstr_defs, args.include_deprecated
            )
